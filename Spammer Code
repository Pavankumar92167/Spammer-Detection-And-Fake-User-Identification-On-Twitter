import tkinter as tk
from tkinter import Tk
from tkinter.filedialog import askopenfilename
import pandas as pd
import numpy as np
from sklearn.naive_bayes import MultinomialNB
from sklearn.svm import LinearSVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt
from collections import OrderedDict
from xgboost import XGBClassifier

# Initialize global variables
filename = None
ErrorrateMeans = []
AccuracyMeans = []

# Browse for a file
def browse():
    global filename
    filename = askopenfilename(filetypes=[("CSV Files", "*.csv")])
    print(f"File Selected: {filename}")

# Create a manual input window
def Create_Input_Window():
    input_window = tk.Toplevel(root)
    input_window.geometry("400x600")
    input_window.resizable(0, 0)
    input_window.title("Manual Input")

    def retrieve_input():
        inputframe = pd.DataFrame(
            OrderedDict({
                'UserID': [e1.get()],
                'No Of Abuse Report': [e2.get()],
                'Rejected Friend Requests': [e3.get()],
                'No Of Friend Requests That Are Not Accepted': [e4.get()],
                'No Of Friends': [e5.get()],
                'No Of Followers': [e6.get()],
                'No Of Likes To Unknown Account': [e7.get()],
                'No Of Comments Per Day': [e8.get()],
            })
        )
        # Reorder columns to match dataset
        inputframe = inputframe[['UserID', 'No Of Abuse Report', 'Rejected Friend Requests',
                                 'No Of Friend Requests That Are Not Accepted', 'No Of Friends',
                                 'No Of Followers', 'No Of Likes To Unknown Account',
                                 'No Of Comments Per Day']]
        return inputframe

    def show_predicted_label(label):
        result_text = "Account Type: Fake" if label == 1 else "Account Type: Not Fake"
        tk.Label(input_window, text=result_text, font="Helvetica 14 bold").grid(row=18, columnspan=2)

    def predict_with_model(model_class):
        if not filename:
            print("No file selected")
            return
        try:
            inputframe = retrieve_input()
            df = pd.read_csv(filename)
            msk = np.random.rand(len(df)) < 0.7
            train = df[msk]
            test = inputframe
            features = train.values[:, :-1]
            labels = train.values[:, -1].astype('int')
            testing_data = test.values[:, :-1]  # Remove target column here

            model = model_class()
            model.fit(features, labels)
            prediction = model.predict(testing_data)
            print(f"Predicted Class: {prediction[0]}")
            show_predicted_label(prediction[0])
        except Exception as e:
            print(f"Error in prediction: {e}")

    # Create entry fields
    tk.Label(input_window, text="Enter Values", font="Helvetica 16 bold").grid(row=0, column=0, columnspan=2)
    labels = ["UserID", "No Of Abuse Report", "Rejected Friend Requests",
              "No Of Friend Requests That Are Not Accepted", "No Of Friends",
              "No Of Followers", "No Of Likes To Unknown Account", "No Of Comments Per Day"]
    entries = []
    for i, text in enumerate(labels):
        tk.Label(input_window, text=text).grid(row=i+1, column=0, pady=5, padx=10, sticky="w")
        entry = tk.Entry(input_window)
        entry.grid(row=i+1, column=1, pady=5, padx=10)
        entries.append(entry)
    e1, e2, e3, e4, e5, e6, e7, e8 = entries

    # Buttons for prediction
    tk.Button(input_window, text="Naive Bayes", command=lambda: predict_with_model(MultinomialNB),
              bg="light steel blue", font="Helvetica 10 bold").grid(row=17, column=0, pady=10, padx=5)
    tk.Button(input_window, text="Linear SVC", command=lambda: predict_with_model(LinearSVC),
              bg="misty rose", font="Helvetica 10 bold").grid(row=17, column=1, pady=10, padx=5)
    tk.Button(input_window, text="KNN", command=lambda: predict_with_model(lambda: KNeighborsClassifier(n_neighbors=3)),
              bg="salmon1", font="Helvetica 10 bold").grid(row=17, column=2, pady=10, padx=5)

# Classifier functions with Hyperparameter tuning
def Naive_Bayes():
    global AccuracyMeans, ErrorrateMeans
    if not filename:
        print("No file selected")
        return
    try:
        df = pd.read_csv(filename)
        train, test = split_data(df)
        model = MultinomialNB()
        evaluate_model(model, train, test, "Naive Bayes", scale=False)
    except Exception as e:
        print(f"Error in Naive Bayes: {e}")

def Linear_Svc():
    global AccuracyMeans, ErrorrateMeans
    if not filename:
        print("No file selected")
        return
    try:
        df = pd.read_csv(filename)
        train, test = split_data(df)
        model = LinearSVC()
        evaluate_model(model, train, test, "Linear SVC")
    except Exception as e:
        print(f"Error in Linear SVC: {e}")

def Knn():
    global AccuracyMeans, ErrorrateMeans
    if not filename:
        print("No file selected")
        return
    try:
        df = pd.read_csv(filename)
        train, test = split_data(df)
        model = KNeighborsClassifier(n_neighbors=3)
        evaluate_model(model, train, test, "KNN")
    except Exception as e:
        print(f"Error in KNN: {e}")

def Random_Forest():
    global AccuracyMeans, ErrorrateMeans
    if not filename:
        print("No file selected")
        return
    try:
        df = pd.read_csv(filename)
        train, test = split_data(df)
        model = RandomForestClassifier(n_estimators=100, random_state=42)
        evaluate_model(model, train, test, "Random Forest")
    except Exception as e:
        print(f"Error in Random Forest: {e}")

def XGBoost():
    global AccuracyMeans, ErrorrateMeans
    if not filename:
        print("No file selected")
        return
    try:
        df = pd.read_csv(filename)
        train, test = split_data(df)
        model = XGBClassifier(use_label_encoder=False, eval_metric="mlogloss")
        evaluate_model(model, train, test, "XGBoost")
    except Exception as e:
        print(f"Error in XGBoost: {e}")

def split_data(df):
    msk = np.random.rand(len(df)) < 0.7
    train = df[msk]
    test = df[~msk]
    return train, test

def evaluate_model(model, train, test, model_name, scale=True):
    features = train.values[:, :-1]
    labels = train.values[:, -1].astype('int')
    testing_data = test.values[:, :-1]  # Use only features (remove target column)
    testing_labels = test.values[:, -1].astype('int')

    # Standardize the features for models like LinearSVC and KNN
    if scale:
        scaler = StandardScaler()
        features = scaler.fit_transform(features)
        testing_data = scaler.transform(testing_data)

    model.fit(features, labels)
    predictions = model.predict(testing_data)

    accuracy = accuracy_score(testing_labels, predictions) * 100
    error_rate = 100 - accuracy
    precision = precision_score(testing_labels, predictions) * 100
    recall = recall_score(testing_labels, predictions) * 100

    AccuracyMeans.append(accuracy)
    ErrorrateMeans.append(error_rate)

    print(f"{model_name}:\n")
    print(f"Confusion Matrix:\n{confusion_matrix(testing_labels, predictions)}")
    print(f"Accuracy: {accuracy:.2f}%")
    print(f"Error Rate: {error_rate:.2f}%")
    print(f"Precision: {precision:.2f}%")
    print(f"Recall: {recall:.2f}%\n")

    # Plotting results
    plot_results(accuracy, error_rate, model_name)

def plot_results(accuracy, error_rate, model_name):
    labels = ["Error Rate", "Accuracy"]
    sizes = [error_rate, accuracy]
    explode = (0, 0.1)
    fig, ax = plt.subplots()
    ax.pie(sizes, explode=explode, labels=labels, autopct='%1.1f%%', shadow=True, startangle=90)
    plt.title(f"{model_name} Algorithm")
    ax.axis("equal")
    plt.show()

# Compare classifiers
def compare():
    ind = np.arange(len(AccuracyMeans))
    width = 0.35

    fig, ax = plt.subplots()
    ax.bar(ind, AccuracyMeans, width, label='Accuracy')
    ax.bar(ind, ErrorrateMeans, width, bottom=AccuracyMeans, label='Error Rate')

    ax.set_ylabel('Scores')
    ax.set_title('Performance by Classifiers')
    ax.set_xticks(ind)
    ax.set_xticklabels(['Naive Bayes', 'Linear SVC', 'KNN', 'Random Forest', 'XGBoost'])
    ax.legend()

    plt.show()

# Main GUI
root = tk.Tk()
root.title("Twitter Fake Account Detector")
root.geometry("600x500")
root.resizable(0, 0)

tk.Label(root, text="Fake Account Detector", fg="dark violet", bg="light blue",
         font="Helvetica 25 bold italic", pady=10).pack()

browse_button = tk.Button(root, text="Browse File", fg="blue", bg="thistle",
                          font="Helvetica 15 bold", command=browse)
browse_button.pack(pady=10)

manual_input_button = tk.Button(root, text="Give Manual Input", bg="LightGoldenRod1",
                                 font="Helvetica 12 bold", command=Create_Input_Window)
manual_input_button.pack(pady=10)

classifier_frame = tk.Frame(root)
classifier_frame.pack(pady=20)

nb_button = tk.Button(classifier_frame, text="Naive Bayes", bg="light steel blue",
                      font="Helvetica 12 bold", command=Naive_Bayes)
nb_button.grid(row=0, column=0, padx=10)

svc_button = tk.Button(classifier_frame, text="Linear SVC", bg="misty rose",
                       font="Helvetica 12 bold", command=Linear_Svc)
svc_button.grid(row=0, column=1, padx=10)

knn_button = tk.Button(classifier_frame, text="KNN", bg="salmon1",
                       font="Helvetica 12 bold", command=Knn)
knn_button.grid(row=0, column=2, padx=10)

rf_button = tk.Button(classifier_frame, text="Random Forest", bg="light green",
                      font="Helvetica 12 bold", command=Random_Forest)
rf_button.grid(row=1, column=0, padx=10)

xgb_button = tk.Button(classifier_frame, text="XGBoost", bg="light pink",
                       font="Helvetica 12 bold", command=XGBoost)
xgb_button.grid(row=1, column=1, padx=10)

compare_button = tk.Button(root, text="Compare Classifiers", bg="light green",
                           font="Helvetica 12 bold", command=compare)
compare_button.pack(pady=20)

root.mainloop()
